# Bert 檢測總結能力效果

## Bert Score 各方法效能指標摘要

| 方法                              | 錯判率  | ROC AUC | 統計檢定結果 (t-test / Wilcoxon)                                       |
|-----------------------------------|---------|---------|-------------------------------------------------------------------------|
| 全文切半取平均                   | 4.20 %  | 0.893   | t = 36.47 (p ≈ 7.1e-143)<br>W = 992 (p ≈ 4.7e-81) → 雙檢定皆顯著 (α=0.01) |
| 篩選 token < 512                 | 1.67 %  | 0.974   | t = 16.07 (p ≈ 3.2e-23)<br>W = 2 (p ≈ 1.8e-11) → 雙檢定皆顯著 (α=0.01)     |
| Chunk size = 512 (大, 中, 小平均) | 2.20 %  | 0.885   | t = 36.74 (p ≈ 5.0e-144)<br>W = 606 (p ≈ 4.7e-82) → 雙檢定皆顯著 (α=0.01)   |
| Chunk size = 512 (top 3)         | 1.80 %  | 0.896   | t = 37.98 (p ≈ 2.5e-149)<br>W = 537 (p ≈ 3.1e-82) → 雙檢定皆顯著 (α=0.01)   |
| Chunk size = 512 (low 3)         | 4.60 %  | 0.856   | t = 33.23 (p ≈ 1.5e-128)<br>W = 1372 (p ≈ 4.4e-80) → 雙檢定皆顯著 (α=0.01)  |

從上方表格可以看到（token 長度、top 3）能顯著降低錯判並提升 ROC AUC。
過往在進行總結能力的評估時常會使用 ROUGE 來評判資訊保留度。因此下方為 Bert 模組加入 Rouge 進行更全方面的評估。下方介紹評分邏輯。

### 🔍 評分邏輯

> 綜合分數 = α × BERTScore_F1 + (1 - α) × 加權 ROUGE F1

- **ROUGE 部分**：原文會切成兩段，計算 `rouge1`, `rouge2`, `rougeL` 的加權平均，反映摘要與原文在關鍵詞層面的重疊程度。
- **BERTScore 部分**：將原文切片為多段，每段最多 `chunk` 個 token，計算與摘要的語意相似度，再取前 ３ 高分段的平均，強調摘要抓住原文的語意核心。
- 內建繁體中文的簡易預處理與停用詞過濾（基於 `jieba`）以提升 ROUGE 精度。　

經實驗綜合效果可達下表:

| 方法                              | 錯判率  | ROC AUC | 統計檢定結果 (t-test / Wilcoxon)                                       |
|-----------------------------------|---------|---------|-------------------------------------------------------------------------|
| Rouge + Bert（chunk 512、top 3）                 | 0.80 %  | 0.925   | t = 39.7737, p = 7.6178e-157 <br> W = 120, p = 2.5996e-83 → 雙檢定皆顯著 (α=0.01) |
